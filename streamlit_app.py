import streamlit as st
import pandas as pd
import numpy as np

st.set_page_config(page_title="Global Earthquakes Dashboard", page_icon="ğŸŒ", layout="wide")
st.title("ğŸŒ ì‹¤ì‹œê°„ ì§€ì§„ ëŒ€ì‹œë³´ë“œ (USGS)")

# --- Controls ---
col0, col1, col2, col3 = st.columns([1.2,1,1,1])
with col0:
    period = st.selectbox("ê¸°ê°„", ["ìµœê·¼ 24ì‹œê°„", "ìµœê·¼ 7ì¼", "ìµœê·¼ 30ì¼"], index=1)
with col1:
    mag_class = st.selectbox("ê·œëª¨ êµ¬ê°„", ["ì „ì²´(all)", "M2.5+", "M4.5+", "Significant"])
with col2:
    min_mag = st.slider("ìµœì†Œ ê·œëª¨(ì¶”ê°€ í•„í„°)", 0.0, 8.0, 0.0, 0.1)
with col3:
    q = st.text_input("ì§€ì—­ í‚¤ì›Œë“œ(ì˜ˆ: Japan, Alaska ë“±)", "")

period_map = {"ìµœê·¼ 24ì‹œê°„": "day", "ìµœê·¼ 7ì¼": "week", "ìµœê·¼ 30ì¼": "month"}
mag_map = {"ì „ì²´(all)": "all", "M2.5+": "2.5", "M4.5+": "4.5", "Significant": "significant"}
url = f"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/{mag_map[mag_class]}_{period_map[period]}.csv"

@st.cache_data(show_spinner=False)
def load(url):
    df = pd.read_csv(url)
    # í‘œì¤€ ì»¬ëŸ¼ ì •ë¦¬
    df["time"] = pd.to_datetime(df["time"])
    df = df.rename(columns={"latitude":"lat", "longitude":"lon", "mag":"magnitude"})
    return df

with st.spinner("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
    df = load(url)

# --- Filtering ---
f = df.copy()
if q:
    f = f[f["place"].str.contains(q, case=False, na=False)]
f = f[f["magnitude"] >= min_mag]

# --- KPIs ---
c1, c2, c3, c4 = st.columns(4)
c1.metric("ì´ë²¤íŠ¸ ìˆ˜", f"{len(f):,}")
c2.metric("ìµœëŒ€ ê·œëª¨", f"{f['magnitude'].max():.1f}" if len(f) else "-")
c3.metric("í‰ê·  ê·œëª¨", f"{f['magnitude'].mean():.2f}" if len(f) else "-")
c4.metric("í‰ê·  ê¹Šì´(km)", f"{f['depth'].mean():.1f}" if len(f) else "-")

st.divider()

# --- Layout: Map + Charts ---
mcol, rcol = st.columns([1.2, 1])
with mcol:
    st.subheader("ğŸ“ ìœ„ì¹˜(ì§€ëª…ì€ place ì»¬ëŸ¼)")
    if len(f):
        # st.mapì€ lat/lon í•„ìš”
        st.map(f[["lat","lon"]], use_container_width=True)
    else:
        st.info("í‘œì‹œí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")

with rcol:
    st.subheader("ğŸ”¢ ê·œëª¨ íˆìŠ¤í† ê·¸ë¨")
    if len(f):
        hist = np.histogram(f["magnitude"].dropna(), bins=20, range=(0, max(8, f["magnitude"].max())))
        st.bar_chart(pd.DataFrame({"count": hist[0]}, index=pd.Index(hist[1][:-1], name="mag")), use_container_width=True)
    else:
        st.empty()

    st.subheader("â±ï¸ ì‹œê°„ëŒ€ë³„ ë°œìƒ ìˆ˜")
    if len(f):
        ts = f.set_index("time").resample("3H")["id"].count()
        st.line_chart(ts, use_container_width=True)
    else:
        st.empty()

# --- Data view & download ---
with st.expander("ì›ë³¸ ë°ì´í„° ë³´ê¸° / ë‹¤ìš´ë¡œë“œ"):
    st.dataframe(f[["time","magnitude","depth","place","lat","lon","type","status","id"]], use_container_width=True)
    st.download_button("CSV ë‹¤ìš´ë¡œë“œ", f.to_csv(index=False).encode("utf-8"), "earthquakes_filtered.csv", "text/csv")

st.caption("ë°ì´í„° ì¶œì²˜: USGS Earthquake Hazards Program ì‹¤ì‹œê°„ í”¼ë“œ(ê¸°ê°„/ê·œëª¨ë³„ CSV).")
